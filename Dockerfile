# Generated by precisionFDA exporter (v1.0.3) on 2018-06-14 16:47:41 +0000
# The asset download links in this file are valid only for 24h.

# Exported app: vcfeval-happy-comparison-vcfcheck, revision: 7, authored by: justin.zook
# https://precision.fda.gov/apps/app-F187Zbj0qXjb85Yq2B6P61zb

# For more information please consult the app export section in the precisionFDA docs

# Start with Ubuntu 14.04 base image
FROM ubuntu:14.04

# Install default precisionFDA Ubuntu packages
RUN DEBIAN_FRONTEND=noninteractive apt-get update && apt-get install -y \
	aria2 \
	byobu \
	cmake \
	cpanminus \
	curl \
	dstat \
	g++ \
	git \
	htop \
	libboost-all-dev \
	libcurl4-openssl-dev \
	libncurses5-dev \
	make \
	perl \
	pypy \
	python-dev \
	python-pip \
	r-base \
	ruby1.9.3 \
	wget \
	xz-utils

# Install default precisionFDA python packages
RUN pip install \
	requests==2.5.0 \
	futures==2.2.0 \
	setuptools==10.2

# Add DNAnexus repo to apt-get
RUN /bin/bash -c "echo 'deb http://dnanexus-apt-prod.s3.amazonaws.com/ubuntu trusty/amd64/' > /etc/apt/sources.list.d/dnanexus.list"
RUN /bin/bash -c "echo 'deb http://dnanexus-apt-prod.s3.amazonaws.com/ubuntu trusty/all/' >> /etc/apt/sources.list.d/dnanexus.list"
RUN curl https://wiki.dnanexus.com/images/files/ubuntu-signing-key.gpg | apt-key add -

# Update apt-get
RUN DEBIAN_FRONTEND=noninteractive apt-get update

# Download app assets
RUN curl https://dl.dnanex.us/F/D/8Z8q38kV25pFV73jFVG6y65yQ2fjVj2908Q1B5xk/hap.py-HAP-207.tar.gz | tar xzf - -C / --no-same-owner --no-same-permissions
RUN curl https://dl.dnanex.us/F/D/qp5bQgKvb4YBKp879YGk8Xzz5q0gBX9XB4VKbX56/hs37d5-fasta.tar.gz | tar xzf - -C / --no-same-owner --no-same-permissions
RUN curl https://dl.dnanex.us/F/D/vbYZPz3pG7yv4jy8FQXvV4bz8xVZx8jbqvB26JPP/htslib-1.3.tar.gz | tar xzf - -C / --no-same-owner --no-same-permissions
RUN curl https://dl.dnanex.us/F/D/p5zyXkQfVbgK6gz3g3KzGZQVyYk66zKBxKkqXbjX/pysam-0.9.1-pandas-0.18.1-numpy-1.11.0-Cython-0.24.tar.gz | tar xzf - -C / --no-same-owner --no-same-permissions
RUN curl https://dl.dnanex.us/F/D/V5Z3XfQb6kY0yf6PXG8FPQFkZ7fPvfGbz64j6P37/rtg-hs37d5.tar | tar xf - -C / --no-same-owner --no-same-permissions
RUN curl https://dl.dnanex.us/F/D/FV20yPPzgPQB6b3p97kG7bg2zqjyVjkQFy664qfK/rtgtools-3.6-dev-ga4gh.tar.gz | tar xzf - -C / --no-same-owner --no-same-permissions

# Download helper executables
RUN curl https://dl.dnanex.us/F/D/0K8P4zZvjq9vQ6qV0b6QqY1z2zvfZ0QKQP4gjBXp/emit-1.0.tar.gz | tar xzf - -C /usr/bin/ --no-same-owner --no-same-permissions
RUN curl https://dl.dnanex.us/F/D/bByKQvv1F7BFP3xXPgYXZPZjkXj9V684VPz8gb7p/run-1.2.tar.gz | tar xzf - -C /usr/bin/ --no-same-owner --no-same-permissions

# Write app spec and code to root folder
RUN ["/bin/bash","-c","echo -E \\{\\\"spec\\\":\\{\\\"input_spec\\\":\\[\\{\\\"name\\\":\\\"query_vcf\\\",\\\"class\\\":\\\"file\\\",\\\"optional\\\":false,\\\"label\\\":\\\"Query\\ VCF\\\",\\\"help\\\":\\\"The\\ GRCh37-based\\ VCF\\ \\(ideally\\ compressed\\ with\\ bgzip\\)\\ with\\ the\\ query\\ \\(test\\ set\\)\\ variants\\\"\\},\\{\\\"name\\\":\\\"truth_vcf\\\",\\\"class\\\":\\\"file\\\",\\\"optional\\\":false,\\\"label\\\":\\\"Truth\\ VCF\\\",\\\"help\\\":\\\"The\\ GRCh37-based\\ VCF\\ \\(ideally\\ compressed\\ with\\ bgzip\\)\\ with\\ the\\ truth\\ \\(benchmark\\ set\\)\\ variants\\\"\\},\\{\\\"name\\\":\\\"truth_bed\\\",\\\"class\\\":\\\"file\\\",\\\"optional\\\":false,\\\"label\\\":\\\"Truth\\ BED\\\",\\\"help\\\":\\\"A\\ BED\\ file\\ with\\ the\\ GRCh37\\ coordinates\\ corresponding\\ to\\ confident\\ regions\\ of\\ the\\ truth\\ VCF\\\"\\},\\{\\\"name\\\":\\\"stratification_beds\\\",\\\"class\\\":\\\"file\\\",\\\"optional\\\":false,\\\"label\\\":\\\"Stratification\\ BED\\ files\\\",\\\"help\\\":\\\"A\\ tar.gz\\ with\\ files.tsv\\ in\\ the\\ bed_files\\ directory\\ describing\\ \\\",\\\"default\\\":\\\"file-F186Gqj0F3YzvYp91zK1QB54\\\"\\}\\],\\\"output_spec\\\":\\[\\{\\\"name\\\":\\\"extended_csv\\\",\\\"class\\\":\\\"file\\\",\\\"optional\\\":false,\\\"label\\\":\\\"Extended\\ CSV\\ stats\\\",\\\"help\\\":\\\"A\\ CSV\\ file\\ with\\ extended\\ statistics\\ as\\ output\\ by\\ the\\ comparator\\\"\\},\\{\\\"name\\\":\\\"archived_results\\\",\\\"class\\\":\\\"file\\\",\\\"optional\\\":false,\\\"label\\\":\\\"Results\\ archive\\\",\\\"help\\\":\\\"An\\ archive\\ containing\\ all\\ the\\ results\\ as\\ output\\ by\\ the\\ comparator\\\"\\}\\],\\\"internet_access\\\":false,\\\"instance_type\\\":\\\"himem-8\\\"\\},\\\"assets\\\":\\[\\\"file-BxfG8x00qVb40P5vk4X8xX3f\\\",\\\"file-Bk5y43Q0qVb0gjfqY8f9k4g8\\\",\\\"file-BpBq6GQ0qVb40z0FGk4ZYjkY\\\",\\\"file-BxfFBK00qVb2XxX8X9FVxj50\\\",\\\"file-BqB6zV80qVb8Xb31P0B97jPg\\\",\\\"file-BvkQ5V8079PYVvxV3j9b9GQq\\\"\\],\\\"packages\\\":\\[\\]\\} \u003e /spec.json"]
RUN ["/bin/bash","-c","echo -E \\{\\\"code\\\":\\\"\\#\\ Use\\ htsfile\\ to\\ sniff\\ the\\ file\\ type\\ of\\ each\\ given\\ VCF\\\\nquery_kind\\=\\$\\(htsfile\\ \\\\\\\"\\$query_vcf_path\\\\\\\"\\ \\|\\ cut\\ -f2\\)\\\\ntruth_kind\\=\\$\\(htsfile\\ \\\\\\\"\\$truth_vcf_path\\\\\\\"\\ \\|\\ cut\\ -f2\\)\\\\n\\\\n\\#\\ Check\\ the\\ query\\ VCF\\ for\\ any\\ required\\ compression\\ or\\ indexing\\\\nif\\ \\[\\[\\ \\\\\\\"\\$query_kind\\\\\\\"\\ \\=\\~\\ \\'variant\\ calling\\ text\\'\\$\\ \\]\\]\\;\\ then\\\\n\\ \\ bgzip\\ \\\\\\\"\\$query_vcf_path\\\\\\\"\\\\n\\ \\ query_vcf_path\\=\\\\\\\"\\$query_vcf_path\\\\\\\".gz\\\\n\\ \\ tabix\\ -p\\ vcf\\ \\\\\\\"\\$query_vcf_path\\\\\\\"\\\\nelif\\ \\[\\[\\ \\\\\\\"\\$query_kind\\\\\\\"\\ \\=\\~\\ \\'gzip-compressed\\ variant\\ calling\\ data\\'\\$\\ \\]\\]\\;\\ then\\\\n\\ \\ zcat\\ \\\\\\\"\\$query_vcf_path\\\\\\\"\\ \\|\\ bgzip\\ \\\\u003etmpfile\\\\n\\ \\ mv\\ -f\\ tmpfile\\ \\\\\\\"\\$query_vcf_path\\\\\\\"\\\\n\\ \\ tabix\\ -p\\ vcf\\ \\\\\\\"\\$query_vcf_path\\\\\\\"\\\\nelif\\ \\[\\[\\ \\\\\\\"\\$query_kind\\\\\\\"\\ \\=\\~\\ \\'BGZF-compressed\\ variant\\ calling\\ data\\'\\$\\ \\]\\]\\;\\ then\\\\n\\ \\ tabix\\ -p\\ vcf\\ \\\\\\\"\\$query_vcf_path\\\\\\\"\\\\nelse\\\\n\\ \\ echo\\ \\\\\\\"Invalid\\ query\\ VCF\\ file\\ \\(\\$query_kind\\)\\\\\\\"\\\\n\\ \\ exit\\ 1\\\\nfi\\\\n\\\\n\\#\\ Check\\ the\\ truth\\ VCF\\ for\\ any\\ required\\ compression\\ or\\ indexing\\\\nif\\ \\[\\[\\ \\\\\\\"\\$truth_kind\\\\\\\"\\ \\=\\~\\ \\'variant\\ calling\\ text\\'\\$\\ \\]\\]\\;\\ then\\\\n\\ \\ bgzip\\ \\\\\\\"\\$truth_vcf_path\\\\\\\"\\\\n\\ \\ truth_vcf_path\\=\\\\\\\"\\$truth_vcf_path\\\\\\\".gz\\\\n\\ \\ tabix\\ -p\\ vcf\\ \\\\\\\"\\$truth_vcf_path\\\\\\\"\\\\nelif\\ \\[\\[\\ \\\\\\\"\\$truth_kind\\\\\\\"\\ \\=\\~\\ \\'gzip-compressed\\ variant\\ calling\\ data\\'\\$\\ \\]\\]\\;\\ then\\\\n\\ \\ zcat\\ \\\\\\\"\\$truth_vcf_path\\\\\\\"\\ \\|\\ bgzip\\ \\\\u003etmpfile\\\\n\\ \\ mv\\ -f\\ tmpfile\\ \\\\\\\"\\$truth_vcf_path\\\\\\\"\\\\n\\ \\ tabix\\ -p\\ vcf\\ \\\\\\\"\\$truth_vcf_path\\\\\\\"\\\\nelif\\ \\[\\[\\ \\\\\\\"\\$truth_kind\\\\\\\"\\ \\=\\~\\ \\'BGZF-compressed\\ variant\\ calling\\ data\\'\\$\\ \\]\\]\\;\\ then\\\\n\\ \\ tabix\\ -p\\ vcf\\ \\\\\\\"\\$truth_vcf_path\\\\\\\"\\\\nelse\\\\n\\ \\ echo\\ \\\\\\\"Invalid\\ truth\\ VCF\\ file\\ \\(\\$truth_kind\\)\\\\\\\"\\\\n\\ \\ exit\\ 1\\\\nfi\\\\n\\\\ntar\\ -zxf\\ \\\\\\\"\\$stratification_beds_path\\\\\\\"\\\\n\\\\n\\#\\ Hap.py\\ requires\\ setting\\ this\\ variable\\\\nexport\\ HGREF\\=\\$HOME/hs37d5.fa\\\\n\\\\n\\\\n\\#\\ Run\\ hap.py\\\\n/opt/hap.py-HAP-207/bin/hap.py\\ \\\\\\\\\\\\n\\ \\ --no-fixchr-truth\\ \\\\\\\\\\\\n\\ \\ --no-fixchr-query\\ \\\\\\\\\\\\n\\ \\ --pass-only\\ \\\\\\\\\\\\n\\ \\ --no-auto-index\\ \\\\\\\\\\\\n\\ \\ -r\\ ./hs37d5.fa\\ \\\\\\\\\\\\n\\ \\ --stratification\\ ./bed_files/files.tsv\\ \\\\\\\\\\\\n\\ \\ --engine\\ vcfeval\\ \\\\\\\\\\\\n\\ \\ --engine-vcfeval-path\\ /opt/rtg-tools-3.6-dev-2365fac/rtg\\ \\\\\\\\\\\\n\\ \\ --engine-vcfeval-template\\ ./hs37d5.sdf/\\ \\\\\\\\\\\\n\\ \\ -f\\ \\\\\\\"\\$truth_bed_path\\\\\\\"\\ \\\\\\\\\\\\n\\ \\ -o\\ \\\\\\\"output\\\\\\\"\\ \\\\\\\\\\\\n\\ \\ \\\\\\\"\\$truth_vcf_path\\\\\\\"\\ \\\\\\\\\\\\n\\ \\ \\\\\\\"\\$query_vcf_path\\\\\\\"\\\\n\\\\nemit\\ extended_csv\\ \\\\\\\"output.extended.csv\\\\\\\"\\\\ntar\\ zcvf\\ output-archive.tar.gz\\ output.\\*\\\\nemit\\ archived_results\\ \\\\\\\"output-archive.tar.gz\\\\\\\"\\\"\\} | python -c 'import sys,json; print json.load(sys.stdin)[\"code\"]' \u003e /script.sh"]

# Create directory /work and set it to $HOME and CWD
RUN mkdir -p /work
ENV HOME="/work"
WORKDIR /work

# Set entry point to container
ENTRYPOINT ["/usr/bin/run"]

VOLUME /data
VOLUME /work